{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecjeffery/Documents/Playgrounds/Python/TFT_TGN/env/lib/python3.11/site-packages/pytorch_forecasting/models/base_model.py:27: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecjeffery/Documents/Playgrounds/Python/TFT_TGN/env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/Users/alecjeffery/Documents/Playgrounds/Python/TFT_TGN/env/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/Users/alecjeffery/Documents/Playgrounds/Python/TFT_TGN/env/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params in network: 32358.6k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecjeffery/Documents/Playgrounds/Python/TFT_TGN/env/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mar3_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 173\u001b[39m\n\u001b[32m    163\u001b[39m trainer = Trainer(\n\u001b[32m    164\u001b[39m     max_epochs=\u001b[32m35\u001b[39m,   \u001b[38;5;66;03m# set higher for real training\u001b[39;00m\n\u001b[32m    165\u001b[39m     accelerator=\u001b[33m\"\u001b[39m\u001b[33mgpu\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DEVICE == \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    169\u001b[39m     callbacks=[early_stop_callback, checkpoint_callback],\n\u001b[32m    170\u001b[39m )\n\u001b[32m    172\u001b[39m \u001b[38;5;66;03m# --- Load the saved state dict ---\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m state_dict = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelPath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m tft_module.load_state_dict(state_dict)\n\u001b[32m    175\u001b[39m tft_module.to(DEVICE)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Playgrounds/Python/TFT_TGN/env/lib/python3.11/site-packages/torch/serialization.py:1425\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1423\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1426\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1427\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1428\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1429\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1430\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Playgrounds/Python/TFT_TGN/env/lib/python3.11/site-packages/torch/serialization.py:751\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[32m    750\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m751\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Playgrounds/Python/TFT_TGN/env/lib/python3.11/site-packages/torch/serialization.py:732\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'mar3_model.pth'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_forecasting.data import TimeSeriesDataSet\n",
    "from pytorch_forecasting.models import TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import MultiLoss\n",
    "from pytorch_forecasting.data.encoders import MultiNormalizer, TorchNormalizer\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "### Model Path\n",
    "modelPath=\"models/mar3_model.pth\"\n",
    "\n",
    "###\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_float32_matmul_precision(\"medium\")  # For NVIDIA Tensor Cores\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Data Loading\n",
    "# -----------------------------\n",
    "def load_data(folder):\n",
    "    all_files = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.csv')]\n",
    "    dfs = []\n",
    "    for file in all_files:\n",
    "        # df = pd.read_csv(file, index_col=0)  # When There is no Date index\n",
    "        df = pd.read_csv(file)\n",
    "        df=df.reset_index(drop=True)\n",
    "        df=df.drop('date',axis=1) # Drops 'date' column\n",
    "        df[\"time_idx\"] = range(len(df))\n",
    "        df[\"group\"] = os.path.basename(file).split('.')[0]\n",
    "        df[\"group\"] = df[\"group\"].astype(str)\n",
    "        df.rename(columns={\"Close\": \"target_1\", \"vclose\": \"target_2\"}, inplace=True)\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "train_data_folder = \"data/train\"\n",
    "test_data_folder  = \"data/test\"\n",
    "oos_data_folder   = \"data/oos\"\n",
    "\n",
    "train_df = load_data(train_data_folder)\n",
    "test_df  = load_data(test_data_folder)\n",
    "oos_df   = load_data(oos_data_folder)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Multi-Target Dataset\n",
    "# -----------------------------\n",
    "training = TimeSeriesDataSet(\n",
    "    train_df,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=[\"target_1\", \"target_2\"],\n",
    "    group_ids=[\"group\"],\n",
    "    max_encoder_length=90,\n",
    "    max_prediction_length=5,\n",
    "    static_categoricals=[\"group\"],\n",
    "    time_varying_known_reals=[\"time_idx\"],\n",
    "    time_varying_unknown_reals=[\n",
    "        c for c in train_df.columns if c not in [\"group\", \"time_idx\"]#, \"target_1\", \"target_2\"]\n",
    "    ],\n",
    "    target_normalizer=MultiNormalizer([\n",
    "        TorchNormalizer(method=\"identity\"),\n",
    "        TorchNormalizer(method=\"identity\")\n",
    "    ])\n",
    ")\n",
    "\n",
    "# validation & OOS sets with predict_mode=False -> keep target data\n",
    "validation = TimeSeriesDataSet.from_dataset(training, test_df, predict_mode=False)\n",
    "oos        = TimeSeriesDataSet.from_dataset(training, oos_df,  predict_mode=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. DataLoaders\n",
    "# -----------------------------\n",
    "train_dataloader = training.to_dataloader(\n",
    "    train=True, batch_size=64, shuffle=True, num_workers=16, pin_memory=False\n",
    ")\n",
    "val_dataloader = validation.to_dataloader(\n",
    "    train=False, batch_size=64, shuffle=False, num_workers=16, pin_memory=False\n",
    ")\n",
    "oos_dataloader = oos.to_dataloader(\n",
    "    train=False, batch_size=16, shuffle=False, num_workers=16, pin_memory=False\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Define Multi-Target TFT Model w/ Quantile Loss\n",
    "# -----------------------------\n",
    "import torch.nn as nn\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=4.171863120490385e-05,\n",
    "    lstm_layers=2,\n",
    "    hidden_size=256,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.35,\n",
    "    hidden_continuous_size=256,\n",
    "    output_size=[1, 1],  # single output per target for MSE\n",
    "    loss=MultiLoss([\n",
    "        nn.MSELoss(),\n",
    "        nn.MSELoss()\n",
    "    ]),\n",
    "    log_interval=200,\n",
    "    reduce_on_plateau_patience=5,\n",
    ").to(DEVICE)\n",
    "\n",
    "print(f\"Number of params in network: {tft.size() / 1e3:.1f}k\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. LightningModule\n",
    "# -----------------------------\n",
    "class TFTLightningModule(LightningModule):\n",
    "    def __init__(self, tft_model):\n",
    "        super().__init__()\n",
    "        self.tft_model = tft_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.tft_model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # 'y' is a tuple: ([target0_tensor, target1_tensor], None)\n",
    "        out = self(x)\n",
    "        pred = out[\"prediction\"]  # list: 0 => target0, 1 => target1\n",
    "        loss = self.tft_model.loss(pred, y)  # automatically handles multi-target\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self(x)\n",
    "        pred = out[\"prediction\"]\n",
    "        loss = self.tft_model.loss(pred, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.tft_model.configure_optimizers()\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        # If the batch is a (x, y) tuple, we only pass x to the model\n",
    "        if isinstance(batch, (tuple, list)):\n",
    "            x = batch[0]\n",
    "        else:\n",
    "            x = batch\n",
    "        return self(x)\n",
    "\n",
    "tft_module = TFTLightningModule(tft).to(DEVICE)\n",
    "\n",
    "# Optional: training setup\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", patience=7, mode=\"min\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints/\",\n",
    "    filename=\"my-tft-{epoch:02d}-{val_loss:.2f}\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=35,   # set higher for real training\n",
    "    accelerator=\"gpu\" if DEVICE == \"cuda\" else \"cpu\",\n",
    "    devices=1,\n",
    "    precision=32,\n",
    "    logger=CSVLogger(\"logs\", name=\"tft_multi_target_quantile\"),\n",
    "    callbacks=[early_stop_callback, checkpoint_callback],\n",
    ")\n",
    "\n",
    "# --- Load the saved state dict ---\n",
    "state_dict = torch.load(modelPath, map_location=DEVICE)\n",
    "tft_module.load_state_dict(state_dict)\n",
    "tft_module.to(DEVICE)\n",
    "tft_module.eval()  # set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict w/ loaded model. RSM ranking from validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing CSCO ...\n",
      "Processing ISRG ...\n",
      "Processing BA ...\n",
      "Processing VRTX ...\n",
      "Processing GILD ...\n",
      "Processing EQIX ...\n",
      "Processing MDT ...\n",
      "Processing V ...\n",
      "Processing MO ...\n",
      "Processing CDNS ...\n",
      "Processing HCA ...\n",
      "Processing AJG ...\n",
      "Processing C ...\n",
      "Processing T ...\n",
      "Processing APH ...\n",
      "Processing MSI ...\n",
      "Processing FCX ...\n",
      "Processing BAC ...\n",
      "Processing PSX ...\n",
      "Processing ADI ...\n",
      "Processing ADBE ...\n",
      "Processing CPRT ...\n",
      "Processing TDG ...\n",
      "Processing SYK ...\n",
      "Processing CB ...\n",
      "Processing NOW ...\n",
      "Processing LLY ...\n",
      "Processing COST ...\n",
      "Processing LOW ...\n",
      "Processing MDLZ ...\n",
      "Processing BKNG ...\n",
      "Processing MET ...\n",
      "Processing DLR ...\n",
      "Processing TJX ...\n",
      "Processing MPC ...\n",
      "Processing D ...\n",
      "Processing MRK ...\n",
      "Processing NOC ...\n",
      "Processing UNP ...\n",
      "Processing ABBV ...\n",
      "Processing ORCL ...\n",
      "Processing ECL ...\n",
      "Processing SBUX ...\n",
      "Processing AMT ...\n",
      "Processing INTU ...\n",
      "Processing PG ...\n",
      "Processing CAT ...\n",
      "Processing MCD ...\n",
      "Processing AMZN ...\n",
      "Processing INTC ...\n",
      "Processing BDX ...\n",
      "Processing KMI ...\n",
      "Processing WELL ...\n",
      "Processing GM ...\n",
      "Processing TXN ...\n",
      "Processing FI ...\n",
      "Processing TMO ...\n",
      "Processing MMM ...\n",
      "Processing FTNT ...\n",
      "Processing ADSK ...\n",
      "Processing KO ...\n",
      "Processing PCAR ...\n",
      "Processing NEE ...\n",
      "Processing UPS ...\n",
      "Processing ELV ...\n",
      "Processing EMR ...\n",
      "Processing MSFT ...\n",
      "Processing CTAS ...\n",
      "Processing ACN ...\n",
      "Processing CMG ...\n",
      "Processing SHW ...\n",
      "Processing AMAT ...\n",
      "Processing DE ...\n",
      "Processing SPG ...\n",
      "Processing KLAC ...\n",
      "Processing RTX ...\n",
      "Processing NXPI ...\n",
      "Processing PNC ...\n",
      "Processing NVDA ...\n",
      "Processing ROP ...\n",
      "Processing HD ...\n",
      "Processing AON ...\n",
      "Processing ZTS ...\n",
      "Processing FDX ...\n",
      "Processing SCHW ...\n",
      "Processing AZO ...\n",
      "Processing AXP ...\n",
      "Processing DFS ...\n",
      "Processing SO ...\n",
      "Processing CME ...\n",
      "Processing XOM ...\n",
      "Processing AMP ...\n",
      "Processing CVX ...\n",
      "Processing CMCSA ...\n",
      "Processing ICE ...\n",
      "Processing NSC ...\n",
      "Processing NKE ...\n",
      "Processing CMI ...\n",
      "Processing PLD ...\n",
      "Processing IBM ...\n",
      "Processing USB ...\n",
      "Processing BSX ...\n",
      "Processing ITW ...\n",
      "Processing EOG ...\n",
      "Processing KMB ...\n",
      "Processing SPGI ...\n",
      "Processing NEM ...\n",
      "Processing WFC ...\n",
      "Processing GS ...\n",
      "Processing GD ...\n",
      "Processing PM ...\n",
      "Processing MCO ...\n",
      "Processing PANW ...\n",
      "Processing DIS ...\n",
      "Processing GE ...\n",
      "Processing ALL ...\n",
      "Processing ETN ...\n",
      "Processing NFLX ...\n",
      "Processing CVS ...\n",
      "Processing JPM ...\n",
      "Processing ABT ...\n",
      "Processing COF ...\n",
      "Processing PH ...\n",
      "Processing TSLA ...\n",
      "Processing COP ...\n",
      "Processing DHR ...\n",
      "Processing MCK ...\n",
      "Processing GOOGL ...\n",
      "Processing PAYX ...\n",
      "Processing META ...\n",
      "Processing MMC ...\n",
      "Processing SRE ...\n",
      "Processing ORLY ...\n",
      "Processing RCL ...\n",
      "Processing SNPS ...\n",
      "Processing PFE ...\n",
      "Processing DUK ...\n",
      "Processing REGN ...\n",
      "Processing CL ...\n",
      "Processing VZ ...\n",
      "Processing JCI ...\n",
      "Processing AMGN ...\n",
      "Processing ADP ...\n",
      "Processing RSG ...\n",
      "Processing QCOM ...\n",
      "Processing MS ...\n",
      "Processing OKE ...\n",
      "Processing BK ...\n",
      "Processing HWM ...\n",
      "Processing TFC ...\n",
      "Processing AFL ...\n",
      "Processing BRK B ...\n",
      "Processing UNH ...\n",
      "Processing WMB ...\n",
      "Processing AIG ...\n",
      "Processing MA ...\n",
      "Processing HON ...\n",
      "Processing O ...\n",
      "Processing SLB ...\n",
      "Processing TT ...\n",
      "Processing TGT ...\n",
      "Processing AAPL ...\n",
      "Processing APD ...\n",
      "Processing BX ...\n",
      "Processing WMT ...\n",
      "Processing LMT ...\n",
      "Processing KKR ...\n",
      "Processing BMY ...\n",
      "Processing PSA ...\n",
      "Processing MU ...\n",
      "Processing TRV ...\n",
      "Processing AEP ...\n",
      "Processing CI ...\n",
      "Processing JNJ ...\n",
      "Processing WM ...\n",
      "Processing CRM ...\n",
      "Processing PGR ...\n",
      "Processing LRCX ...\n",
      "Processing BLK ...\n",
      "\n",
      "Results DataFrame:\n",
      "    Symbol       MSE     Pred1     Pred2     Pred3     Pred4     Pred5  \\\n",
      "0     CSCO  0.073799  2.228963  2.205342  2.197472  2.198900  2.202812   \n",
      "1     ISRG  0.004205  1.884429  1.887331  1.899634  1.919682  1.941538   \n",
      "2       BA  0.140395  0.551384  0.559629  0.568269  0.589104  0.611944   \n",
      "3     VRTX  0.066153  0.908752  0.885531  0.856358  0.847197  0.858112   \n",
      "4     GILD  0.234858  2.599140  2.504758  2.451344  2.419095  2.401365   \n",
      "..     ...       ...       ...       ...       ...       ...       ...   \n",
      "174     WM  0.058512  2.498276  2.461812  2.417433  2.390239  2.376925   \n",
      "175    CRM  0.008703  0.726581  0.687723  0.663731  0.679475  0.721078   \n",
      "176    PGR  0.026139  1.873076  1.872382  1.873746  1.896719  1.930308   \n",
      "177   LRCX  0.021431  0.071776  0.071463  0.080527  0.111621  0.150098   \n",
      "178    BLK  0.430638  1.045340  1.052952  1.053889  1.066353  1.084257   \n",
      "\n",
      "        Delta  \n",
      "0   -0.026151  \n",
      "1    0.057109  \n",
      "2    0.060560  \n",
      "3   -0.050641  \n",
      "4   -0.197775  \n",
      "..        ...  \n",
      "174 -0.121351  \n",
      "175 -0.005503  \n",
      "176  0.057232  \n",
      "177  0.078322  \n",
      "178  0.038917  \n",
      "\n",
      "[179 rows x 8 columns]\n",
      "\n",
      "Ranked by MSE:\n",
      "    Symbol       MSE     Pred1     Pred2     Pred3     Pred4     Pred5  \\\n",
      "114     GE  0.002473  1.857839  1.842645  1.843751  1.864074  1.888420   \n",
      "1     ISRG  0.004205  1.884429  1.887331  1.899634  1.919682  1.941538   \n",
      "126    MCK  0.005388  1.146410  1.128212  1.112221  1.123402  1.161281   \n",
      "148    HWM  0.005714  1.874273  1.832578  1.819144  1.832610  1.859268   \n",
      "112   PANW  0.006932  1.383082  1.407922  1.427431  1.447760  1.467361   \n",
      "..     ...       ...       ...       ...       ...       ...       ...   \n",
      "162    APD  0.927897  1.119471  1.111449  1.110071  1.124122  1.148553   \n",
      "150    AFL  0.949289  0.618173  0.579612  0.551568  0.565603  0.626799   \n",
      "102    ITW  1.127481  1.250133  1.264702  1.282557  1.332197  1.395409   \n",
      "123   TSLA  1.241562  1.146391  1.121180  1.105012  1.108525  1.123252   \n",
      "152    UNH  2.435796 -1.162530 -1.146399 -1.106329 -1.066894 -1.049152   \n",
      "\n",
      "        Delta  \n",
      "114  0.030581  \n",
      "1    0.057109  \n",
      "126  0.014870  \n",
      "148 -0.015005  \n",
      "112  0.084279  \n",
      "..        ...  \n",
      "162  0.029083  \n",
      "150  0.008625  \n",
      "102  0.145277  \n",
      "123 -0.023139  \n",
      "152  0.113378  \n",
      "\n",
      "[179 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "saveAs = 'RankedPreds_3-02_newModel.csv'\n",
    "\n",
    "mu_sig_df = pd.read_csv('./data/TixMuSig.csv')\n",
    "\n",
    "def move_to_device(batch_x, device):\n",
    "    \"\"\"Ensure all Tensors in batch_x are on the same device.\"\"\"\n",
    "    if isinstance(batch_x, torch.Tensor):\n",
    "        return batch_x.to(device)\n",
    "    elif isinstance(batch_x, dict):\n",
    "        return {k: move_to_device(v, device) for k, v in batch_x.items()}\n",
    "    elif isinstance(batch_x, list):\n",
    "        return [move_to_device(item, device) for item in batch_x]\n",
    "    else:\n",
    "        return batch_x\n",
    "\n",
    "def process_symbol(symbol):\n",
    "    # Filter the full oos dataframe for this symbol (group)\n",
    "    stock_oos_df = oos_df[oos_df[\"group\"] == symbol]\n",
    "    if stock_oos_df.empty:\n",
    "        print(f\"No OOS data for {symbol}.\")\n",
    "        return None\n",
    "\n",
    "    # Retrieve the scaling parameters for price (target_1) from mu_sig_df.\n",
    "    try:\n",
    "        mu_p = mu_sig_df.loc[mu_sig_df['ticker'] == symbol, 'closemu'].values[0]\n",
    "        sig_p = mu_sig_df.loc[mu_sig_df['ticker'] == symbol, 'closesig'].values[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving mu/sig for {symbol}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # Create two datasets:\n",
    "    # 1. For current predictions (no future targets provided)\n",
    "    eq_dataset_current = TimeSeriesDataSet.from_dataset(\n",
    "        training, stock_oos_df, predict_mode=True\n",
    "    )\n",
    "    eq_dataloader_current = eq_dataset_current.to_dataloader(\n",
    "        train=False,\n",
    "        batch_size=len(eq_dataset_current),  # All samples in one batch\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=False\n",
    "    )\n",
    "\n",
    "    # 2. For backtesting (to compute MSE, future values are provided)\n",
    "    eq_dataset_backtest = TimeSeriesDataSet.from_dataset(\n",
    "        training, stock_oos_df, predict_mode=False\n",
    "    )\n",
    "    eq_dataloader_backtest = eq_dataset_backtest.to_dataloader(\n",
    "        train=False,\n",
    "        batch_size=len(eq_dataset_backtest),  # All samples in one batch\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=False\n",
    "    )\n",
    "    # -------------------------------------------------------------------\n",
    "\n",
    "    # --- Get current predictions (using predict_mode=True) ---\n",
    "    with torch.no_grad():\n",
    "        for batch in eq_dataloader_current:\n",
    "            x_current, _ = batch  # y is not used in predict_mode=True\n",
    "            x_current = move_to_device(x_current, DEVICE)\n",
    "            out_current = tft_module(x_current)\n",
    "            preds_current = out_current[\"prediction\"]\n",
    "            # Assuming target_1 is at index 0 and we use the median (index 0 when using MSE)\n",
    "            current_price_preds = preds_current[0][:, :, 0].cpu()  # shape: (batch, prediction_length)\n",
    "\n",
    "    # Extract Pred1–Pred5 from current predictions:\n",
    "    # (Assuming prediction_length is 5 and batch size is 1)\n",
    "    pred1 = current_price_preds[0, 0].item()\n",
    "    pred2 = current_price_preds[0, 1].item()\n",
    "    pred3 = current_price_preds[0, 2].item()\n",
    "    pred4 = current_price_preds[0, 3].item()\n",
    "    pred5 = current_price_preds[0, 4].item()\n",
    "    # print(current_price_preds[0])\n",
    "\n",
    "\n",
    "    # --- Get backtest predictions for MSE calculation (using predict_mode=False) ---\n",
    "    with torch.no_grad():\n",
    "        for batch in eq_dataloader_backtest:\n",
    "            x_backtest, y_tuple = batch\n",
    "            y_list, _ = y_tuple\n",
    "            # Get the actual future values for target_1.\n",
    "            actual_future = y_list[0]  # shape: [batch, prediction_length]\n",
    "            x_backtest = move_to_device(x_backtest, DEVICE)\n",
    "            out_backtest = tft_module(x_backtest)\n",
    "            preds_backtest = out_backtest[\"prediction\"]\n",
    "            backtest_price_preds = preds_backtest[0][:, :, 0].cpu()\n",
    "\n",
    "    # Compute MSE over the forecast horizon using the backtest data.\n",
    "    mse_value = torch.mean((backtest_price_preds[0] - actual_future[0])**2).item()\n",
    "    # plt.plot(backtest_price_preds)\n",
    "    # plt.plot(actual_future)\n",
    "    # plt.show()\n",
    "    # Build the result dictionary.\n",
    "    result = {\n",
    "        \"Symbol\": symbol,\n",
    "        \"MSE\": mse_value,\n",
    "        \"Pred1\": pred1,\n",
    "        \"Pred2\": pred2,\n",
    "        \"Pred3\": pred3,\n",
    "        \"Pred4\": pred4,\n",
    "        \"Pred5\": pred5,\n",
    "        \"Delta\": pred5-pred1,\n",
    "    }\n",
    "    return result\n",
    "\n",
    "# Loop over each CSV file in \"./data/oos\" and collect results.\n",
    "results_list = []\n",
    "oos_folder = \"./data/oos\"\n",
    "oos_files = [f for f in os.listdir(oos_folder) if f.endswith('.csv')]\n",
    "for file in oos_files:#[:6]:\n",
    "    symbol = os.path.splitext(file)[0].upper()\n",
    "    print(f\"Processing {symbol} ...\")\n",
    "    res = process_symbol(symbol)\n",
    "    if res is not None:\n",
    "        results_list.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "print(\"\\nResults DataFrame:\")\n",
    "print(results_df)\n",
    "\n",
    "results_df_sorted = results_df.sort_values(by=\"MSE\")\n",
    "print(\"\\nRanked by MSE:\")\n",
    "print(results_df_sorted)\n",
    "results_df_sorted.to_csv(saveAs, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
